{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yWoRPAm2iqe4"
   },
   "source": [
    "# Flower multi class classifier\n",
    "\n",
    "This is a multi class image classifier which classifier the 3 flower types rose, lotus and sunflower. The keras pre-trained model InceptionV3 will be used which is trained on ImageNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tN8IdwIrjcrl"
   },
   "source": [
    "## Exploring the Pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ucnnVocHjhld"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-24bYXT9j2oG"
   },
   "outputs": [],
   "source": [
    "local_weights_file = '/content/drive/My Drive/Projects/Rose vs sunflower classifier/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPbcWW1BkJV-"
   },
   "outputs": [],
   "source": [
    "pre_trained_model = InceptionV3(input_shape = (300, 300, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4CC-3B8kNgm"
   },
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IGpb4P6kkPnY",
    "outputId": "b594b818-662e-4a90-dc79-527d164c63f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U4zd_aVHkRT_",
    "outputId": "20bb0c7f-5bf7-4a9b-8156-fc45e197dca2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 17, 17, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I_NL2O7AkVY5"
   },
   "source": [
    "## Adding custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jU7vwjKekS0s"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Adding a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "x = layers.Dense (3, activation='softmax')(x)           \n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ulSkFhh9kdTp"
   },
   "source": [
    "## Getting the dataset ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3o_NH8FskbWV"
   },
   "outputs": [],
   "source": [
    "# Defining the directories where the images are present\n",
    "base_dir='Rose vs sunflower classifier'\n",
    "\n",
    "# Directory with the training and testing examples\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Directory with our training pictures\n",
    "train_lotus_dir= os.path.join(train_dir,'lotus')\n",
    "train_rose_dir= os.path.join(train_dir,'rose')\n",
    "train_sunflower_dir= os.path.join(train_dir,'sunflower')\n",
    "\n",
    "# Directory with our testing pictures\n",
    "validation_lotus_dir= os.path.join(validation_dir,'lotus')\n",
    "validation_rose_dir= os.path.join(validation_dir,'rose')\n",
    "validation_sunflower_dir= os.path.join(validation_dir,'sunflower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "G8j7OXWXkxmq",
    "outputId": "8deb26c4-af05-4456-fd21-a8d31e77352a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training lotus images: 550\n",
      "total training rose images: 600\n",
      "total training sunflower images: 600\n",
      "total validation lotus images: 147\n",
      "total validation rose images: 212\n",
      "total validation sunflower images: 241\n"
     ]
    }
   ],
   "source": [
    "print('total training lotus images:', len(os.listdir(train_lotus_dir)))\n",
    "print('total training rose images:', len(os.listdir(train_rose_dir)))\n",
    "print('total training sunflower images:', len(os.listdir(train_sunflower_dir)))\n",
    "\n",
    "print('total validation lotus images:', len(os.listdir(validation_lotus_dir)))\n",
    "print('total validation rose images:', len(os.listdir(validation_rose_dir)))\n",
    "print('total validation sunflower images:', len(os.listdir(validation_sunflower_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z4kfyzE_k2tb"
   },
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4d8YTumk0GH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "uTylWxSdk_oT",
    "outputId": "311e43b1-71d3-40b7-a981-b6c8a123a9c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1750 images belonging to 3 classes.\n",
      "Found 600 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Adding data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator( rescale = 1.0/255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 32,\n",
    "                                                    class_mode = 'categorical', \n",
    "                                                    target_size = (300,300))     \n",
    "\n",
    "validation_generator =  validation_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 32,\n",
    "                                                          class_mode  = 'categorical', \n",
    "                                                          target_size = (300,300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_oM0bsEB0qND"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ue7Hoj8HlIZu",
    "outputId": "9eab48bd-aa61-4039-f99e-1c0b14198e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 116s 58s/step - loss: 11.0264 - accuracy: 0.3750 - val_loss: 2.2719 - val_accuracy: 0.3750\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 114s 57s/step - loss: 9.2662 - accuracy: 0.2969 - val_loss: 7.8343 - val_accuracy: 0.3438\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 117s 59s/step - loss: 5.7380 - accuracy: 0.3594 - val_loss: 2.5749 - val_accuracy: 0.2969\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 102s 51s/step - loss: 2.9919 - accuracy: 0.4062 - val_loss: 0.7416 - val_accuracy: 0.7344\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 100s 50s/step - loss: 1.4592 - accuracy: 0.6250 - val_loss: 0.4334 - val_accuracy: 0.8438\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 111s 55s/step - loss: 0.7331 - accuracy: 0.7031 - val_loss: 0.7307 - val_accuracy: 0.7031\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 51s 25s/step - loss: 1.1400 - accuracy: 0.5938 - val_loss: 0.7769 - val_accuracy: 0.7143\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 30s 15s/step - loss: 0.8906 - accuracy: 0.6250 - val_loss: 0.7957 - val_accuracy: 0.7188\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 28s 14s/step - loss: 0.8602 - accuracy: 0.6250 - val_loss: 0.4744 - val_accuracy: 0.8281\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 29s 15s/step - loss: 0.3629 - accuracy: 0.8125 - val_loss: 0.5616 - val_accuracy: 0.8281\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 36s 18s/step - loss: 0.5595 - accuracy: 0.8125 - val_loss: 0.2243 - val_accuracy: 0.9219\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 28s 14s/step - loss: 0.6766 - accuracy: 0.7656 - val_loss: 0.4258 - val_accuracy: 0.8594\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 29s 14s/step - loss: 1.5396 - accuracy: 0.6562 - val_loss: 0.4534 - val_accuracy: 0.8214\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 30s 15s/step - loss: 0.7510 - accuracy: 0.6562 - val_loss: 0.2184 - val_accuracy: 0.9375\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 31s 15s/step - loss: 0.3983 - accuracy: 0.8906 - val_loss: 0.3414 - val_accuracy: 0.8906\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 33s 17s/step - loss: 0.5572 - accuracy: 0.7188 - val_loss: 0.6030 - val_accuracy: 0.7812\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 29s 15s/step - loss: 1.4827 - accuracy: 0.6094 - val_loss: 1.8696 - val_accuracy: 0.5469\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 32s 16s/step - loss: 1.9390 - accuracy: 0.5156 - val_loss: 0.1394 - val_accuracy: 0.9844\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 31s 16s/step - loss: 0.3330 - accuracy: 0.8438 - val_loss: 0.2674 - val_accuracy: 0.8750\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 28s 14s/step - loss: 0.3799 - accuracy: 0.8750 - val_loss: 0.3127 - val_accuracy: 0.8438\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 38s 19s/step - loss: 0.3610 - accuracy: 0.8438 - val_loss: 0.6386 - val_accuracy: 0.7344\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 27s 14s/step - loss: 1.0525 - accuracy: 0.6250 - val_loss: 0.4184 - val_accuracy: 0.8438\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 30s 15s/step - loss: 0.7619 - accuracy: 0.7656 - val_loss: 0.2900 - val_accuracy: 0.8438\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 31s 15s/step - loss: 0.4263 - accuracy: 0.8125 - val_loss: 0.4024 - val_accuracy: 0.8906\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 27s 13s/step - loss: 0.6095 - accuracy: 0.7656 - val_loss: 1.0987 - val_accuracy: 0.6562\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 27s 13s/step - loss: 1.2127 - accuracy: 0.6250 - val_loss: 0.2869 - val_accuracy: 0.8929\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 32s 16s/step - loss: 0.4105 - accuracy: 0.7969 - val_loss: 0.3038 - val_accuracy: 0.8906\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.3042 - accuracy: 0.8704 - val_loss: 0.1858 - val_accuracy: 0.9219\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2271 - accuracy: 0.9375 - val_loss: 0.3690 - val_accuracy: 0.8438\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5807 - accuracy: 0.8125 - val_loss: 0.3263 - val_accuracy: 0.8750\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5579 - accuracy: 0.7812 - val_loss: 0.1767 - val_accuracy: 0.9219\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.8014 - accuracy: 0.6719 - val_loss: 0.2262 - val_accuracy: 0.9464\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4872 - accuracy: 0.8281 - val_loss: 0.9201 - val_accuracy: 0.7656\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.5913 - accuracy: 0.8125 - val_loss: 0.1989 - val_accuracy: 0.9219\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.7527 - accuracy: 0.6875 - val_loss: 0.2058 - val_accuracy: 0.9531\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.3092 - accuracy: 0.9219 - val_loss: 0.2675 - val_accuracy: 0.8906\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 2s 951ms/step - loss: 0.2211 - accuracy: 0.9375 - val_loss: 0.0844 - val_accuracy: 0.9688\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.4771 - accuracy: 0.7969 - val_loss: 0.2107 - val_accuracy: 0.9062\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.3050 - accuracy: 0.8906 - val_loss: 0.7174 - val_accuracy: 0.7969\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.7397 - accuracy: 0.7344 - val_loss: 0.3061 - val_accuracy: 0.9531\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4886 - accuracy: 0.8438 - val_loss: 0.0937 - val_accuracy: 0.9688\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.6585 - accuracy: 0.7500 - val_loss: 0.2512 - val_accuracy: 0.9219\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.3281 - accuracy: 0.8750 - val_loss: 0.2600 - val_accuracy: 0.8594\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3625 - accuracy: 0.8594 - val_loss: 0.1769 - val_accuracy: 0.9531\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1893 - accuracy: 0.9531 - val_loss: 0.1438 - val_accuracy: 0.9643\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.3653 - accuracy: 0.8281 - val_loss: 0.5215 - val_accuracy: 0.8125\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.7840 - accuracy: 0.7969 - val_loss: 0.2604 - val_accuracy: 0.9062\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.8989 - accuracy: 0.7500 - val_loss: 0.2982 - val_accuracy: 0.9219\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 2s 952ms/step - loss: 0.2164 - accuracy: 0.8594 - val_loss: 0.1740 - val_accuracy: 0.9375\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 2s 906ms/step - loss: 0.3464 - accuracy: 0.8906 - val_loss: 0.1276 - val_accuracy: 0.9531\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.5562 - accuracy: 0.8438 - val_loss: 0.1604 - val_accuracy: 0.9107\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.6445 - accuracy: 0.7812 - val_loss: 0.2346 - val_accuracy: 0.9062\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1874 - accuracy: 0.9375 - val_loss: 0.1507 - val_accuracy: 0.9375\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1490 - accuracy: 0.9375 - val_loss: 0.1776 - val_accuracy: 0.9375\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2429 - accuracy: 0.9259 - val_loss: 0.1929 - val_accuracy: 0.9219\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2915 - accuracy: 0.9062 - val_loss: 0.2656 - val_accuracy: 0.9062\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 2s 853ms/step - loss: 0.1726 - accuracy: 0.9062 - val_loss: 0.1875 - val_accuracy: 0.9375\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 2s 999ms/step - loss: 0.1661 - accuracy: 0.9375 - val_loss: 0.4491 - val_accuracy: 0.8281\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 2s 940ms/step - loss: 0.3428 - accuracy: 0.8125 - val_loss: 0.3138 - val_accuracy: 0.8750\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 2s 990ms/step - loss: 0.3771 - accuracy: 0.9219 - val_loss: 0.1650 - val_accuracy: 0.9062\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2495 - accuracy: 0.9219 - val_loss: 0.4582 - val_accuracy: 0.8438\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4554 - accuracy: 0.7656 - val_loss: 0.1268 - val_accuracy: 0.9531\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2920 - accuracy: 0.8750 - val_loss: 0.6178 - val_accuracy: 0.8281\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.9895 - accuracy: 0.7969 - val_loss: 0.0888 - val_accuracy: 0.9643\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2283 - accuracy: 0.9219 - val_loss: 0.1685 - val_accuracy: 0.9375\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2367 - accuracy: 0.9375 - val_loss: 0.3489 - val_accuracy: 0.9062\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 2s 996ms/step - loss: 0.6277 - accuracy: 0.7812 - val_loss: 0.3423 - val_accuracy: 0.8906\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.3171 - accuracy: 0.8906 - val_loss: 0.2250 - val_accuracy: 0.8906\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2337 - accuracy: 0.8438 - val_loss: 0.2067 - val_accuracy: 0.9531\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 2s 956ms/step - loss: 0.1709 - accuracy: 0.9219 - val_loss: 0.2169 - val_accuracy: 0.9107\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4162 - accuracy: 0.8438 - val_loss: 0.2754 - val_accuracy: 0.8594\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2742 - accuracy: 0.8906 - val_loss: 0.1845 - val_accuracy: 0.8750\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 2s 941ms/step - loss: 0.1633 - accuracy: 0.9219 - val_loss: 0.2036 - val_accuracy: 0.9375\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1212 - accuracy: 0.9375 - val_loss: 0.2233 - val_accuracy: 0.9062\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 2s 962ms/step - loss: 0.1634 - accuracy: 0.9688 - val_loss: 0.3582 - val_accuracy: 0.8906\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.0199 - accuracy: 0.7188 - val_loss: 0.1490 - val_accuracy: 0.9375\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4036 - accuracy: 0.8594 - val_loss: 0.2826 - val_accuracy: 0.8906\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4344 - accuracy: 0.8438 - val_loss: 0.1451 - val_accuracy: 0.9219\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.4018 - accuracy: 0.7969 - val_loss: 0.3601 - val_accuracy: 0.9062\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.5005 - accuracy: 0.8750 - val_loss: 0.1257 - val_accuracy: 0.9688\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1389 - accuracy: 0.9531 - val_loss: 0.1407 - val_accuracy: 0.9375\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 2s 990ms/step - loss: 0.3383 - accuracy: 0.8594 - val_loss: 0.3965 - val_accuracy: 0.8750\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 2s 879ms/step - loss: 0.2741 - accuracy: 0.9074 - val_loss: 0.1485 - val_accuracy: 0.9643\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 2s 993ms/step - loss: 0.1919 - accuracy: 0.9062 - val_loss: 0.1269 - val_accuracy: 0.9375\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.3879 - accuracy: 0.8281 - val_loss: 0.3132 - val_accuracy: 0.8750\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4595 - accuracy: 0.8281 - val_loss: 0.1869 - val_accuracy: 0.9219\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1293 - accuracy: 0.9688 - val_loss: 0.1244 - val_accuracy: 0.9531\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.4550 - accuracy: 0.8125 - val_loss: 0.8399 - val_accuracy: 0.8438\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.5755 - accuracy: 0.7969 - val_loss: 0.1389 - val_accuracy: 0.9821\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1826 - accuracy: 0.8750 - val_loss: 0.1346 - val_accuracy: 0.9531\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.3057 - accuracy: 0.9062 - val_loss: 0.4395 - val_accuracy: 0.8594\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.4293 - accuracy: 0.8125 - val_loss: 0.2101 - val_accuracy: 0.9219\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 2s 893ms/step - loss: 0.3846 - accuracy: 0.8906 - val_loss: 0.4784 - val_accuracy: 0.8906\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.1225 - accuracy: 0.9844 - val_loss: 0.1156 - val_accuracy: 0.9375\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.1953 - accuracy: 0.9219 - val_loss: 0.1246 - val_accuracy: 0.9688\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.2794 - accuracy: 0.8750 - val_loss: 0.1030 - val_accuracy: 0.9688\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.2459 - accuracy: 0.8906 - val_loss: 0.0908 - val_accuracy: 0.9531\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 3s 1s/step - loss: 0.4790 - accuracy: 0.8750 - val_loss: 0.2447 - val_accuracy: 0.9062\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 2s 1s/step - loss: 0.3623 - accuracy: 0.8594 - val_loss: 0.2340 - val_accuracy: 0.9531\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 2s 920ms/step - loss: 0.1529 - accuracy: 0.9375 - val_loss: 0.2179 - val_accuracy: 0.9219\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = len(train_dir)//32,\n",
    "            epochs = 100,\n",
    "            validation_steps = len(validation_dir)//32,\n",
    "            verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NA7Aatr91CCQ"
   },
   "source": [
    "## Evaluating Accuracy and Loss for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "GUq197ZulUGw",
    "outputId": "b890ff76-2bf1-45fc-ead8-35beb8cc345c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "snZjewcBFy_7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "rose_vs_sunflower.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
